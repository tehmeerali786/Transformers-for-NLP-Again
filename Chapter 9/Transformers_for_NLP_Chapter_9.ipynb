{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers for NLP Chapter 9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMA-DtgS3uPz"
      },
      "source": [
        "## Semanti Role Labeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwsvuFo4cJFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d959df-9899-460d-8296-2ce2430ccf61"
      },
      "source": [
        "!pip install allennlp==1.0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting allennlp==1.0.0\n",
            "  Downloading allennlp-1.0.0-py3-none-any.whl (473 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20 kB 31.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 30 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 51 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 71 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 81 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 92 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 102 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 112 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 122 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 133 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 143 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 153 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 163 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 174 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 184 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 194 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 204 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 215 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 225 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 235 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 245 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 256 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 266 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 276 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 286 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 296 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 307 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 317 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 327 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 337 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 348 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 358 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 368 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 378 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 389 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 399 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 409 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 419 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 430 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 440 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 450 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 460 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 471 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 473 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting torch<1.6.0,>=1.5.0\n",
            "  Downloading torch-1.5.1-cp37-cp37m-manylinux1_x86_64.whl (753.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.2 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0) (1.4.1)\n",
            "Collecting transformers<2.12,>=2.9\n",
            "  Downloading transformers-2.11.0-py3-none-any.whl (674 kB)\n",
            "\u001b[K     |████████████████████████████████| 674 kB 34.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0) (2.2.4)\n",
            "Collecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0) (3.2.5)\n",
            "Collecting filelock<3.1,>=3.0\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0) (3.1.0)\n",
            "Collecting jsonpickle\n",
            "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting overrides==3.0.0\n",
            "  Downloading overrides-3.0.0.tar.gz (4.5 kB)\n",
            "Collecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.17.0.tar.gz (259 kB)\n",
            "\u001b[K     |████████████████████████████████| 259 kB 41.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0) (1.19.5)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0) (3.6.4)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0) (0.22.2.post1)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.19.2-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 55.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.0.0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.3,>=2.1.0->allennlp==1.0.0) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.3,>=2.1.0->allennlp==1.0.0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.3,>=2.1.0->allennlp==1.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.2->allennlp==1.0.0) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX>=1.2->allennlp==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch<1.6.0,>=1.5.0->allennlp==1.0.0) (0.16.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 34.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "  Downloading tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 27.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (21.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 43.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (2019.12.20)\n",
            "Collecting botocore<1.23.0,>=1.22.2\n",
            "  Downloading botocore-1.22.2-py3-none-any.whl (8.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 40.4 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.23.0,>=1.22.2->boto3->allennlp==1.0.0) (2.8.2)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 56.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp==1.0.0) (1.5.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<2.12,>=2.9->allennlp==1.0.0) (2.4.7)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.0.0) (8.10.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.0.0) (1.10.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.0.0) (21.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<2.12,>=2.9->allennlp==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<2.12,>=2.9->allennlp==1.0.0) (1.0.1)\n",
            "Building wheels for collected packages: overrides, jsonnet\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.0.0-py3-none-any.whl size=5673 sha256=b389482f42cd2ee3380db5e4de2c6d036f93f161eb1781169adc4aeecd3c3b32\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/c6/bf/bff44a9cc6c899e2d77ec968b2d0707616a3d66e4ebefb2411\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.17.0-cp37-cp37m-linux_x86_64.whl size=3388687 sha256=13377ef8c1d2efeb17e9946d824e5d7cb94cc19672d03702ba9cf32c760656c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/28/7e/287c6b19f7161bb03c6986a3c46b51d0d7d9a1805346634e3a\n",
            "Successfully built overrides jsonnet\n",
            "Installing collected packages: urllib3, jmespath, botocore, tokenizers, sentencepiece, sacremoses, s3transfer, filelock, transformers, torch, tensorboardX, overrides, jsonpickle, jsonnet, boto3, allennlp\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.3.0\n",
            "    Uninstalling filelock-3.3.0:\n",
            "      Successfully uninstalled filelock-3.3.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu111\n",
            "    Uninstalling torch-1.9.0+cu111:\n",
            "      Successfully uninstalled torch-1.9.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu111 requires torch==1.9.0, but you have torch 1.5.1 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.5.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed allennlp-1.0.0 boto3-1.19.2 botocore-1.22.2 filelock-3.0.12 jmespath-0.10.0 jsonnet-0.17.0 jsonpickle-2.0.0 overrides-3.0.0 s3transfer-0.5.0 sacremoses-0.0.46 sentencepiece-0.1.96 tensorboardX-2.4 tokenizers-0.7.0 torch-1.5.1 transformers-2.11.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThEFdQeC5QAF",
        "outputId": "090950f3-5d00-48c8-fb7a-156c2f9ccd1a"
      },
      "source": [
        "!pip install allennlp-models==1.0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting allennlp-models==1.0.0\n",
            "  Downloading allennlp_models-1.0.0-py3-none-any.whl (282 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 51 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 61 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 71 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 81 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 92 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 102 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 112 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 122 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 143 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 153 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 163 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 174 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 184 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 194 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 204 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 215 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 225 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 235 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 245 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 256 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 266 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 276 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 282 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp-models==1.0.0) (3.2.5)\n",
            "Collecting py-rouge==1.1\n",
            "  Downloading py_rouge-1.1-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting conllu==3.0\n",
            "  Downloading conllu-3.0-py2.py3-none-any.whl (14 kB)\n",
            "Collecting word2number>=1.1\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "Requirement already satisfied: allennlp==1.0.0 in /usr/local/lib/python3.7/dist-packages (from allennlp-models==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: spacy<2.3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (2.2.4)\n",
            "Requirement already satisfied: transformers<2.12,>=2.9 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (2.11.0)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: torch<1.6.0,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (1.5.1)\n",
            "Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (1.19.2)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (2.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: overrides==3.0.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (0.22.2.post1)\n",
            "Requirement already satisfied: jsonnet>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (0.17.0)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (4.62.3)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (2.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (3.6.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.0.0->allennlp-models==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.0.0->allennlp-models==1.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.0.0->allennlp-models==1.0.0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==1.0.0->allennlp-models==1.0.0) (1.25.11)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.2->allennlp==1.0.0->allennlp-models==1.0.0) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX>=1.2->allennlp==1.0.0->allennlp-models==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch<1.6.0,>=1.5.0->allennlp==1.0.0->allennlp-models==1.0.0) (0.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (0.1.96)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (0.0.46)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.7/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (0.7.0)\n",
            "Requirement already satisfied: botocore<1.23.0,>=1.22.2 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp==1.0.0->allennlp-models==1.0.0) (1.22.2)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp==1.0.0->allennlp-models==1.0.0) (0.5.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp==1.0.0->allennlp-models==1.0.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.23.0,>=1.22.2->boto3->allennlp==1.0.0->allennlp-models==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp==1.0.0->allennlp-models==1.0.0) (1.5.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (2.4.7)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.0.0->allennlp-models==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.0.0->allennlp-models==1.0.0) (1.10.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.0.0->allennlp-models==1.0.0) (8.10.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.0.0->allennlp-models==1.0.0) (21.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==1.0.0->allennlp-models==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (1.0.1)\n",
            "Building wheels for collected packages: word2number\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5580 sha256=0c836c835d19f3fb817870b4d03e18e5f556a5b8da0f9c2d2ec2efc0d114c592\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/c3/77/a5f48aeb0d3efb7cd5ad61cbd3da30bbf9ffc9662b07c9f879\n",
            "Successfully built word2number\n",
            "Installing collected packages: word2number, py-rouge, conllu, allennlp-models\n",
            "Successfully installed allennlp-models-1.0.0 conllu-3.0 py-rouge-1.1 word2number-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am7FuIzGbjLz"
      },
      "source": [
        "Sample 1: Did Bob really think he could prepare a meal for 50 people in only a few hours?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymz3HZc56jyQ",
        "outputId": "8dc4e9b8-911e-4c04-ff05-59a17670f6dc"
      },
      "source": [
        "!echo '{\"sentence\": \"Did Bob think really he could prepare a meal for 50 people in only a few hours?\"}' | \\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-24 22:37:48,275 - INFO - transformers.file_utils - PyTorch version 1.5.1 available.\n",
            "2021-10-24 22:37:51,160 - INFO - transformers.file_utils - TensorFlow version 2.6.0 available.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "2021-10-24 22:37:55,031 - INFO - allennlp.common.file_utils - checking cache for https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:37:55,032 - INFO - allennlp.common.file_utils - waiting to acquire lock on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:37:55,032 - INFO - filelock - Lock 140344941079376 acquired on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2021-10-24 22:37:55,032 - INFO - allennlp.common.file_utils - https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz not found in cache, downloading to /root/.allennlp/cache/tmpq075okyc.tmp\n",
            "100% 406056588/406056588 [00:08<00:00, 45946530.66B/s]\n",
            "2021-10-24 22:38:04,128 - INFO - allennlp.common.file_utils - Renaming temp file /root/.allennlp/cache/tmpq075okyc.tmp to cache at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:38:04,129 - INFO - allennlp.common.file_utils - creating metadata file for /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:38:04,129 - INFO - filelock - Lock 140344941079376 released on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2021-10-24 22:38:04,129 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz from cache at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:38:04,129 - INFO - allennlp.models.archival - extracting archive file /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724 to temp dir /tmp/tmpyx1185re\n",
            "2021-10-24 22:38:08,552 - INFO - allennlp.common.params - type = from_instances\n",
            "2021-10-24 22:38:08,552 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpyx1185re/vocabulary.\n",
            "2021-10-24 22:38:08,553 - INFO - filelock - Lock 140344938268048 acquired on /tmp/tmpyx1185re/vocabulary/.lock\n",
            "2021-10-24 22:38:08,579 - INFO - filelock - Lock 140344938268048 released on /tmp/tmpyx1185re/vocabulary/.lock\n",
            "2021-10-24 22:38:08,579 - INFO - allennlp.common.params - model.type = srl_bert\n",
            "2021-10-24 22:38:08,580 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2021-10-24 22:38:08,580 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
            "2021-10-24 22:38:08,580 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
            "2021-10-24 22:38:08,580 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fa49a358fd0>\n",
            "2021-10-24 22:38:08,580 - INFO - allennlp.common.params - model.label_smoothing = None\n",
            "2021-10-24 22:38:08,580 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
            "2021-10-24 22:38:08,580 - INFO - allennlp.common.params - model.srl_eval_path = /usr/local/lib/python3.7/dist-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
            "2021-10-24 22:38:08,874 - INFO - filelock - Lock 140344922210256 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "2021-10-24 22:38:08,875 - INFO - transformers.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpcj69jjcs\n",
            "Downloading: 100% 433/433 [00:00<00:00, 301kB/s]\n",
            "2021-10-24 22:38:09,193 - INFO - transformers.file_utils - storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2021-10-24 22:38:09,194 - INFO - transformers.file_utils - creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2021-10-24 22:38:09,194 - INFO - filelock - Lock 140344922210256 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "2021-10-24 22:38:09,194 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2021-10-24 22:38:09,195 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "2021-10-24 22:38:09,319 - INFO - filelock - Lock 140344922209936 acquired on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "2021-10-24 22:38:09,319 - INFO - transformers.file_utils - https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpx1dh9j48\n",
            "Downloading: 100% 440M/440M [00:13<00:00, 33.6MB/s]\n",
            "2021-10-24 22:38:22,477 - INFO - transformers.file_utils - storing https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2021-10-24 22:38:22,477 - INFO - transformers.file_utils - creating metadata file for /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2021-10-24 22:38:22,478 - INFO - filelock - Lock 140344922209936 released on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "2021-10-24 22:38:22,478 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2021-10-24 22:38:25,517 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2021-10-24 22:38:25,518 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2021-10-24 22:38:25,518 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
            "2021-10-24 22:38:25,518 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
            "2021-10-24 22:38:25,518 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
            "2021-10-24 22:38:25,518 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
            "2021-10-24 22:38:25,518 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
            "2021-10-24 22:38:25,518 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,518 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,518 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
            "2021-10-24 22:38:25,518 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
            "2021-10-24 22:38:25,519 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
            "2021-10-24 22:38:25,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
            "2021-10-24 22:38:25,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
            "2021-10-24 22:38:25,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
            "2021-10-24 22:38:25,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
            "2021-10-24 22:38:25,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
            "2021-10-24 22:38:25,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
            "2021-10-24 22:38:25,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
            "2021-10-24 22:38:25,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
            "2021-10-24 22:38:25,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
            "2021-10-24 22:38:25,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
            "2021-10-24 22:38:25,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
            "2021-10-24 22:38:25,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
            "2021-10-24 22:38:25,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
            "2021-10-24 22:38:25,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
            "2021-10-24 22:38:25,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
            "2021-10-24 22:38:25,526 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
            "2021-10-24 22:38:25,526 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
            "2021-10-24 22:38:25,526 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
            "2021-10-24 22:38:25,526 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
            "2021-10-24 22:38:25,565 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
            "2021-10-24 22:38:25,565 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
            "2021-10-24 22:38:25,565 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
            "2021-10-24 22:38:25,565 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,565 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,565 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
            "2021-10-24 22:38:25,565 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
            "2021-10-24 22:38:25,565 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,565 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,565 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
            "2021-10-24 22:38:25,565 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
            "2021-10-24 22:38:25,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
            "2021-10-24 22:38:25,567 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
            "2021-10-24 22:38:25,567 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
            "2021-10-24 22:38:25,567 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2021-10-24 22:38:25,567 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2021-10-24 22:38:25,567 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
            "2021-10-24 22:38:25,567 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
            "2021-10-24 22:38:25,567 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
            "2021-10-24 22:38:25,567 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
            "2021-10-24 22:38:25,567 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
            "2021-10-24 22:38:25,567 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
            "2021-10-24 22:38:26,139 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
            "2021-10-24 22:38:26,139 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-10-24 22:38:26,140 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-10-24 22:38:26,140 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-10-24 22:38:26,140 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-10-24 22:38:26,140 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-10-24 22:38:26,140 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
            "2021-10-24 22:38:26,140 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
            "2021-10-24 22:38:26,140 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
            "2021-10-24 22:38:26,447 - INFO - filelock - Lock 140344938268112 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "2021-10-24 22:38:26,448 - INFO - transformers.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp7l8kx3ic\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 897kB/s]\n",
            "2021-10-24 22:38:27,000 - INFO - transformers.file_utils - storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "2021-10-24 22:38:27,000 - INFO - transformers.file_utils - creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "2021-10-24 22:38:27,001 - INFO - filelock - Lock 140344938268112 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "2021-10-24 22:38:27,001 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "input 0:  {\"sentence\": \"Did Bob think really he could prepare a meal for 50 people in only a few hours?\"}\n",
            "prediction:  {\"verbs\": [{\"verb\": \"think\", \"description\": \"Did [ARG0: Bob] [V: think] [ARG1: really he could prepare a meal for 50 people in only a few hours] ?\", \"tags\": [\"O\", \"B-ARG0\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\"]}, {\"verb\": \"could\", \"description\": \"Did Bob think really he [V: could] prepare a meal for 50 people in only a few hours ?\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"prepare\", \"description\": \"Did Bob think [ARGM-ADV: really] [ARG0: he] [ARGM-MOD: could] [V: prepare] [ARG1: a meal for 50 people] [ARGM-TMP: in only a few hours] ?\", \"tags\": [\"O\", \"O\", \"O\", \"B-ARGM-ADV\", \"B-ARG0\", \"B-ARGM-MOD\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"B-ARGM-TMP\", \"I-ARGM-TMP\", \"I-ARGM-TMP\", \"I-ARGM-TMP\", \"I-ARGM-TMP\", \"O\"]}], \"words\": [\"Did\", \"Bob\", \"think\", \"really\", \"he\", \"could\", \"prepare\", \"a\", \"meal\", \"for\", \"50\", \"people\", \"in\", \"only\", \"a\", \"few\", \"hours\", \"?\"]}\n",
            "\n",
            "2021-10-24 22:38:28,555 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpyx1185re\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozf9U4hHc_Eg"
      },
      "source": [
        "Sample 2: Mr. and Mrs. Tomaso went to Europe for vacation and visited Paris and first went to visit the Eiffel Tower"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoUZKxsD7TZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb594aa1-1ad4-4596-c7d4-e226a9fb777e"
      },
      "source": [
        "!echo '{\"sentence\": \"Mr. and Mrs. Tomaso went to Europe for vacation and visited Paris and first went to visit the Eiffel Tower\"}'|\\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-24 22:39:22,888 - INFO - transformers.file_utils - PyTorch version 1.5.1 available.\n",
            "2021-10-24 22:39:24,760 - INFO - transformers.file_utils - TensorFlow version 2.6.0 available.\n",
            "2021-10-24 22:39:26,068 - INFO - allennlp.common.file_utils - checking cache for https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:39:26,068 - INFO - allennlp.common.file_utils - waiting to acquire lock on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:39:26,069 - INFO - filelock - Lock 140132191506256 acquired on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2021-10-24 22:39:26,069 - INFO - allennlp.common.file_utils - cache of https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz is up-to-date\n",
            "2021-10-24 22:39:26,069 - INFO - filelock - Lock 140132191506256 released on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2021-10-24 22:39:26,069 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz from cache at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:39:26,069 - INFO - allennlp.models.archival - extracting archive file /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724 to temp dir /tmp/tmpq0x8sys3\n",
            "2021-10-24 22:39:30,591 - INFO - allennlp.common.params - type = from_instances\n",
            "2021-10-24 22:39:30,591 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpq0x8sys3/vocabulary.\n",
            "2021-10-24 22:39:30,591 - INFO - filelock - Lock 140128868897872 acquired on /tmp/tmpq0x8sys3/vocabulary/.lock\n",
            "2021-10-24 22:39:30,615 - INFO - filelock - Lock 140128868897872 released on /tmp/tmpq0x8sys3/vocabulary/.lock\n",
            "2021-10-24 22:39:30,616 - INFO - allennlp.common.params - model.type = srl_bert\n",
            "2021-10-24 22:39:30,616 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2021-10-24 22:39:30,616 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
            "2021-10-24 22:39:30,616 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
            "2021-10-24 22:39:30,616 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f724b788ed0>\n",
            "2021-10-24 22:39:30,617 - INFO - allennlp.common.params - model.label_smoothing = None\n",
            "2021-10-24 22:39:30,617 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
            "2021-10-24 22:39:30,617 - INFO - allennlp.common.params - model.srl_eval_path = /usr/local/lib/python3.7/dist-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
            "2021-10-24 22:39:30,896 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2021-10-24 22:39:30,897 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "2021-10-24 22:39:30,954 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2021-10-24 22:39:34,056 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2021-10-24 22:39:34,057 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2021-10-24 22:39:34,057 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
            "2021-10-24 22:39:34,057 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
            "2021-10-24 22:39:34,057 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
            "2021-10-24 22:39:34,057 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
            "2021-10-24 22:39:34,057 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,058 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
            "2021-10-24 22:39:34,059 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
            "2021-10-24 22:39:34,060 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
            "2021-10-24 22:39:34,061 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,062 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,062 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
            "2021-10-24 22:39:34,062 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
            "2021-10-24 22:39:34,062 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,062 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,062 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
            "2021-10-24 22:39:34,062 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
            "2021-10-24 22:39:34,062 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
            "2021-10-24 22:39:34,062 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
            "2021-10-24 22:39:34,062 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
            "2021-10-24 22:39:34,062 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
            "2021-10-24 22:39:34,062 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
            "2021-10-24 22:39:34,076 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
            "2021-10-24 22:39:34,076 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
            "2021-10-24 22:39:34,076 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
            "2021-10-24 22:39:34,076 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,076 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,076 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
            "2021-10-24 22:39:34,076 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
            "2021-10-24 22:39:34,076 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,076 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,076 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
            "2021-10-24 22:39:34,076 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
            "2021-10-24 22:39:34,076 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
            "2021-10-24 22:39:34,076 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
            "2021-10-24 22:39:34,077 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
            "2021-10-24 22:39:34,078 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
            "2021-10-24 22:39:34,078 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
            "2021-10-24 22:39:34,078 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
            "2021-10-24 22:39:34,078 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2021-10-24 22:39:34,078 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2021-10-24 22:39:34,078 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
            "2021-10-24 22:39:34,078 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
            "2021-10-24 22:39:34,078 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
            "2021-10-24 22:39:34,078 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
            "2021-10-24 22:39:34,078 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
            "2021-10-24 22:39:34,078 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
            "2021-10-24 22:39:34,864 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
            "2021-10-24 22:39:34,864 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-10-24 22:39:34,864 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-10-24 22:39:34,864 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-10-24 22:39:34,864 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-10-24 22:39:34,864 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-10-24 22:39:34,865 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
            "2021-10-24 22:39:34,865 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
            "2021-10-24 22:39:34,865 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
            "2021-10-24 22:39:35,152 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "input 0:  {\"sentence\": \"Mr. and Mrs. Tomaso went to Europe for vacation and visited Paris and first went to visit the Eiffel Tower\"}\n",
            "prediction:  {\"verbs\": [{\"verb\": \"went\", \"description\": \"[ARG0: Mr. and Mrs. Tomaso] [V: went] [ARG4: to Europe] [ARGM-PRP: for vacation] and visited Paris and first went to visit the Eiffel Tower\", \"tags\": [\"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"B-V\", \"B-ARG4\", \"I-ARG4\", \"B-ARGM-PRP\", \"I-ARGM-PRP\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"visited\", \"description\": \"[ARG0: Mr. and Mrs. Tomaso] went to Europe for vacation and [V: visited] [ARG1: Paris] and first went to visit the Eiffel Tower\", \"tags\": [\"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"went\", \"description\": \"[ARG0: Mr. and Mrs. Tomaso] went to Europe for vacation and visited Paris and [ARGM-TMP: first] [V: went] [ARGM-PRP: to visit the Eiffel Tower]\", \"tags\": [\"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARGM-TMP\", \"B-V\", \"B-ARGM-PRP\", \"I-ARGM-PRP\", \"I-ARGM-PRP\", \"I-ARGM-PRP\", \"I-ARGM-PRP\"]}, {\"verb\": \"visit\", \"description\": \"[ARG0: Mr. and Mrs. Tomaso] went to Europe for vacation and visited Paris and first went to [V: visit] [ARG1: the Eiffel Tower]\", \"tags\": [\"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\"]}], \"words\": [\"Mr.\", \"and\", \"Mrs.\", \"Tomaso\", \"went\", \"to\", \"Europe\", \"for\", \"vacation\", \"and\", \"visited\", \"Paris\", \"and\", \"first\", \"went\", \"to\", \"visit\", \"the\", \"Eiffel\", \"Tower\"]}\n",
            "\n",
            "2021-10-24 22:39:36,844 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpq0x8sys3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZhn3xHSeBi9"
      },
      "source": [
        "Sample 3: John wanted to drink tea, Marry likes to drink coffee but Karim drank some cool water and Faiza would like to drink tomato juice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y71ejyE_dU19",
        "outputId": "115da391-dfb3-4f67-ceb3-9136a732bd31"
      },
      "source": [
        "!echo '{\"sentence\": \"John wanted to drink tea, Marry likes to drink coffee but Karim drank some cool water and Faiza would like to drink tomato juice.\"}' |\\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-24 22:42:05,753 - INFO - transformers.file_utils - PyTorch version 1.5.1 available.\n",
            "2021-10-24 22:42:07,624 - INFO - transformers.file_utils - TensorFlow version 2.6.0 available.\n",
            "2021-10-24 22:42:08,884 - INFO - allennlp.common.file_utils - checking cache for https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:42:08,884 - INFO - allennlp.common.file_utils - waiting to acquire lock on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:42:08,885 - INFO - filelock - Lock 140406633518224 acquired on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2021-10-24 22:42:08,885 - INFO - allennlp.common.file_utils - cache of https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz is up-to-date\n",
            "2021-10-24 22:42:08,885 - INFO - filelock - Lock 140406633518224 released on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2021-10-24 22:42:08,885 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz from cache at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:42:08,885 - INFO - allennlp.models.archival - extracting archive file /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724 to temp dir /tmp/tmpetgh7isk\n",
            "2021-10-24 22:42:13,271 - INFO - allennlp.common.params - type = from_instances\n",
            "2021-10-24 22:42:13,271 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpetgh7isk/vocabulary.\n",
            "2021-10-24 22:42:13,271 - INFO - filelock - Lock 140406602069456 acquired on /tmp/tmpetgh7isk/vocabulary/.lock\n",
            "2021-10-24 22:42:13,295 - INFO - filelock - Lock 140406602069456 released on /tmp/tmpetgh7isk/vocabulary/.lock\n",
            "2021-10-24 22:42:13,296 - INFO - allennlp.common.params - model.type = srl_bert\n",
            "2021-10-24 22:42:13,296 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2021-10-24 22:42:13,296 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
            "2021-10-24 22:42:13,296 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
            "2021-10-24 22:42:13,296 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fb2f5a88ed0>\n",
            "2021-10-24 22:42:13,296 - INFO - allennlp.common.params - model.label_smoothing = None\n",
            "2021-10-24 22:42:13,296 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
            "2021-10-24 22:42:13,297 - INFO - allennlp.common.params - model.srl_eval_path = /usr/local/lib/python3.7/dist-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
            "2021-10-24 22:42:13,593 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2021-10-24 22:42:13,593 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "2021-10-24 22:42:13,701 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2021-10-24 22:42:16,424 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2021-10-24 22:42:16,424 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
            "2021-10-24 22:42:16,425 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
            "2021-10-24 22:42:16,426 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
            "2021-10-24 22:42:16,427 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,428 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
            "2021-10-24 22:42:16,429 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
            "2021-10-24 22:42:16,430 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
            "2021-10-24 22:42:16,466 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
            "2021-10-24 22:42:16,466 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
            "2021-10-24 22:42:16,466 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
            "2021-10-24 22:42:16,466 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,466 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,466 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
            "2021-10-24 22:42:16,466 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
            "2021-10-24 22:42:16,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
            "2021-10-24 22:42:16,468 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
            "2021-10-24 22:42:16,469 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
            "2021-10-24 22:42:16,469 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
            "2021-10-24 22:42:17,087 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
            "2021-10-24 22:42:17,088 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-10-24 22:42:17,088 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-10-24 22:42:17,088 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-10-24 22:42:17,088 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-10-24 22:42:17,088 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-10-24 22:42:17,088 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
            "2021-10-24 22:42:17,088 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
            "2021-10-24 22:42:17,088 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
            "2021-10-24 22:42:17,404 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "input 0:  {\"sentence\": \"John wanted to drink tea, Marry likes to drink coffee but Karim drank some cool water and Faiza would like to drink tomato juice.\"}\n",
            "prediction:  {\"verbs\": [{\"verb\": \"wanted\", \"description\": \"[ARG0: John] [V: wanted] [ARG1: to drink tea] , Marry likes to drink coffee but Karim drank some cool water and Faiza would like to drink tomato juice .\", \"tags\": [\"B-ARG0\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"drink\", \"description\": \"[ARG0: John] wanted to [V: drink] [ARG1: tea] , Marry likes to drink coffee but Karim drank some cool water and Faiza would like to drink tomato juice .\", \"tags\": [\"B-ARG0\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"drink\", \"description\": \"[ARG0: John] wanted to drink tea , Marry likes to [V: drink] [ARG1: coffee] but Karim drank some cool water and Faiza would like to drink tomato juice .\", \"tags\": [\"B-ARG0\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"drank\", \"description\": \"John wanted to drink tea , Marry likes to drink coffee but [ARG0: Karim] [V: drank] [ARG1: some cool water and Faiza] would like to drink tomato juice .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"would\", \"description\": \"John wanted to drink tea , Marry likes to drink coffee but Karim drank some cool water and Faiza [V: would] [ARGM-DIS: like] [ARG1: to drink tomato juice] .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARGM-DIS\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\"]}, {\"verb\": \"like\", \"description\": \"John wanted to drink tea , Marry likes to drink coffee but Karim drank [ARG0: some cool water and Faiza] [ARGM-MOD: would] [V: like] [ARG1: to drink tomato juice] .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"B-ARGM-MOD\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\"]}, {\"verb\": \"drink\", \"description\": \"John wanted to drink tea , Marry likes to drink coffee but Karim drank [ARG0: some cool water and Faiza] would like to [V: drink] [ARG1: tomato juice] .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"O\"]}], \"words\": [\"John\", \"wanted\", \"to\", \"drink\", \"tea\", \",\", \"Marry\", \"likes\", \"to\", \"drink\", \"coffee\", \"but\", \"Karim\", \"drank\", \"some\", \"cool\", \"water\", \"and\", \"Faiza\", \"would\", \"like\", \"to\", \"drink\", \"tomato\", \"juice\", \".\"]}\n",
            "\n",
            "2021-10-24 22:42:19,505 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpetgh7isk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeHWFakweSIt"
      },
      "source": [
        "Sample 4: Alice whose husband went jogging every Sunday, liked to go to a dancing class in the meantime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKU2yyMTd8mj",
        "outputId": "8d6a660d-4f62-48d2-ec7e-8c4a0e431b2b"
      },
      "source": [
        "!echo '{\"sentence\": \"Alice whose husband went jogging every Sunday, liked to go to a dancing class in the meantime.\"}'|\\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-24 22:45:32,240 - INFO - transformers.file_utils - PyTorch version 1.5.1 available.\n",
            "2021-10-24 22:45:34,136 - INFO - transformers.file_utils - TensorFlow version 2.6.0 available.\n",
            "2021-10-24 22:45:35,436 - INFO - allennlp.common.file_utils - checking cache for https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:45:35,437 - INFO - allennlp.common.file_utils - waiting to acquire lock on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:45:35,437 - INFO - filelock - Lock 139883032898640 acquired on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2021-10-24 22:45:35,437 - INFO - allennlp.common.file_utils - cache of https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz is up-to-date\n",
            "2021-10-24 22:45:35,437 - INFO - filelock - Lock 139883032898640 released on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2021-10-24 22:45:35,437 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz from cache at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:45:35,437 - INFO - allennlp.models.archival - extracting archive file /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724 to temp dir /tmp/tmpvkm9ygm0\n",
            "2021-10-24 22:45:39,930 - INFO - allennlp.common.params - type = from_instances\n",
            "2021-10-24 22:45:39,930 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpvkm9ygm0/vocabulary.\n",
            "2021-10-24 22:45:39,930 - INFO - filelock - Lock 139883032492560 acquired on /tmp/tmpvkm9ygm0/vocabulary/.lock\n",
            "2021-10-24 22:45:39,955 - INFO - filelock - Lock 139883032492560 released on /tmp/tmpvkm9ygm0/vocabulary/.lock\n",
            "2021-10-24 22:45:39,955 - INFO - allennlp.common.params - model.type = srl_bert\n",
            "2021-10-24 22:45:39,956 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2021-10-24 22:45:39,956 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
            "2021-10-24 22:45:39,956 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
            "2021-10-24 22:45:39,956 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f390e7b1fd0>\n",
            "2021-10-24 22:45:39,956 - INFO - allennlp.common.params - model.label_smoothing = None\n",
            "2021-10-24 22:45:39,956 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
            "2021-10-24 22:45:39,956 - INFO - allennlp.common.params - model.srl_eval_path = /usr/local/lib/python3.7/dist-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
            "2021-10-24 22:45:40,241 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2021-10-24 22:45:40,241 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "2021-10-24 22:45:40,353 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2021-10-24 22:45:43,062 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2021-10-24 22:45:43,062 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
            "2021-10-24 22:45:43,063 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
            "2021-10-24 22:45:43,064 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,065 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,066 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
            "2021-10-24 22:45:43,067 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
            "2021-10-24 22:45:43,134 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
            "2021-10-24 22:45:43,134 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
            "2021-10-24 22:45:43,134 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
            "2021-10-24 22:45:43,134 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,134 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,134 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
            "2021-10-24 22:45:43,134 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
            "2021-10-24 22:45:43,134 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,134 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
            "2021-10-24 22:45:43,135 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
            "2021-10-24 22:45:43,136 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
            "2021-10-24 22:45:43,813 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
            "2021-10-24 22:45:43,813 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-10-24 22:45:43,813 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-10-24 22:45:43,813 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-10-24 22:45:43,813 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-10-24 22:45:43,814 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-10-24 22:45:43,814 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
            "2021-10-24 22:45:43,814 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
            "2021-10-24 22:45:43,814 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
            "2021-10-24 22:45:44,102 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "input 0:  {\"sentence\": \"Alice whose husband went jogging every Sunday, liked to go to a dancing class in the meantime.\"}\n",
            "prediction:  {\"verbs\": [{\"verb\": \"went\", \"description\": \"Alice [ARG0: whose husband] [V: went] [ARG2: jogging] [ARGM-TMP: every Sunday] , liked to go to a dancing class in the meantime .\", \"tags\": [\"O\", \"B-ARG0\", \"I-ARG0\", \"B-V\", \"B-ARG2\", \"B-ARGM-TMP\", \"I-ARGM-TMP\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"jogging\", \"description\": \"Alice [ARG0: whose husband] went [V: jogging] [ARGM-TMP: every Sunday] , liked to go to a dancing class in the meantime .\", \"tags\": [\"O\", \"B-ARG0\", \"I-ARG0\", \"O\", \"B-V\", \"B-ARGM-TMP\", \"I-ARGM-TMP\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"liked\", \"description\": \"Alice [ARG0: whose husband] went jogging every Sunday , [V: liked] [ARG1: to go to a dancing class in the meantime] .\", \"tags\": [\"O\", \"B-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\"]}, {\"verb\": \"go\", \"description\": \"Alice [ARG0: whose husband] went jogging every Sunday , liked to [V: go] [ARG4: to a dancing class] [ARGM-TMP: in the meantime] .\", \"tags\": [\"O\", \"B-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG4\", \"I-ARG4\", \"I-ARG4\", \"I-ARG4\", \"B-ARGM-TMP\", \"I-ARGM-TMP\", \"I-ARGM-TMP\", \"O\"]}, {\"verb\": \"dancing\", \"description\": \"Alice whose husband went jogging every Sunday , liked to go to a [V: dancing] [ARG0: class] in the meantime .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG0\", \"O\", \"O\", \"O\", \"O\"]}], \"words\": [\"Alice\", \"whose\", \"husband\", \"went\", \"jogging\", \"every\", \"Sunday\", \",\", \"liked\", \"to\", \"go\", \"to\", \"a\", \"dancing\", \"class\", \"in\", \"the\", \"meantime\", \".\"]}\n",
            "\n",
            "2021-10-24 22:45:45,668 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpvkm9ygm0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDwg4WJjgnhW"
      },
      "source": [
        "Sample 5: The bright sun, the blue sky, the warm send, the palm trees, everything round off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE5VbQtyevAi",
        "outputId": "6d480401-f1c5-46b8-e26e-ed6d8626e10d"
      },
      "source": [
        "!echo '{\"sentence\": \"The bright sun, the blue sky, the warm send, the palm trees, everything round off.\"}' | \\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-24 22:52:28,630 - INFO - transformers.file_utils - PyTorch version 1.5.1 available.\n",
            "2021-10-24 22:52:30,538 - INFO - transformers.file_utils - TensorFlow version 2.6.0 available.\n",
            "2021-10-24 22:52:31,781 - INFO - allennlp.common.file_utils - checking cache for https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:52:31,781 - INFO - allennlp.common.file_utils - waiting to acquire lock on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:52:31,781 - INFO - filelock - Lock 139890454885072 acquired on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2021-10-24 22:52:31,781 - INFO - allennlp.common.file_utils - cache of https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz is up-to-date\n",
            "2021-10-24 22:52:31,781 - INFO - filelock - Lock 139890454885072 released on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2021-10-24 22:52:31,781 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz from cache at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:52:31,782 - INFO - allennlp.models.archival - extracting archive file /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724 to temp dir /tmp/tmp6hp3d030\n",
            "2021-10-24 22:52:36,196 - INFO - allennlp.common.params - type = from_instances\n",
            "2021-10-24 22:52:36,196 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmp6hp3d030/vocabulary.\n",
            "2021-10-24 22:52:36,196 - INFO - filelock - Lock 139887133874384 acquired on /tmp/tmp6hp3d030/vocabulary/.lock\n",
            "2021-10-24 22:52:36,222 - INFO - filelock - Lock 139887133874384 released on /tmp/tmp6hp3d030/vocabulary/.lock\n",
            "2021-10-24 22:52:36,222 - INFO - allennlp.common.params - model.type = srl_bert\n",
            "2021-10-24 22:52:36,222 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2021-10-24 22:52:36,222 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
            "2021-10-24 22:52:36,223 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
            "2021-10-24 22:52:36,223 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f3a02f0cd50>\n",
            "2021-10-24 22:52:36,223 - INFO - allennlp.common.params - model.label_smoothing = None\n",
            "2021-10-24 22:52:36,223 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
            "2021-10-24 22:52:36,223 - INFO - allennlp.common.params - model.srl_eval_path = /usr/local/lib/python3.7/dist-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
            "2021-10-24 22:52:36,556 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2021-10-24 22:52:36,557 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "2021-10-24 22:52:36,668 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2021-10-24 22:52:39,390 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
            "2021-10-24 22:52:39,391 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,392 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
            "2021-10-24 22:52:39,393 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
            "2021-10-24 22:52:39,394 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
            "2021-10-24 22:52:39,395 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,396 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
            "2021-10-24 22:52:39,397 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
            "2021-10-24 22:52:39,398 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
            "2021-10-24 22:52:39,399 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
            "2021-10-24 22:52:39,400 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
            "2021-10-24 22:52:39,401 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
            "2021-10-24 22:52:39,401 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
            "2021-10-24 22:52:39,401 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
            "2021-10-24 22:52:39,401 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
            "2021-10-24 22:52:39,401 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2021-10-24 22:52:39,401 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2021-10-24 22:52:39,401 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
            "2021-10-24 22:52:39,401 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
            "2021-10-24 22:52:39,401 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
            "2021-10-24 22:52:39,401 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
            "2021-10-24 22:52:39,401 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
            "2021-10-24 22:52:39,401 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
            "2021-10-24 22:52:40,013 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
            "2021-10-24 22:52:40,013 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-10-24 22:52:40,013 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-10-24 22:52:40,013 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-10-24 22:52:40,013 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-10-24 22:52:40,013 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-10-24 22:52:40,013 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
            "2021-10-24 22:52:40,014 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
            "2021-10-24 22:52:40,014 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
            "2021-10-24 22:52:40,303 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "input 0:  {\"sentence\": \"The bright sun, the blue sky, the warm send, the palm trees, everything round off.\"}\n",
            "prediction:  {\"verbs\": [], \"words\": [\"The\", \"bright\", \"sun\", \",\", \"the\", \"blue\", \"sky\", \",\", \"the\", \"warm\", \"send\", \",\", \"the\", \"palm\", \"trees\", \",\", \"everything\", \"round\", \"off\", \".\"]}\n",
            "\n",
            "2021-10-24 22:52:41,354 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmp6hp3d030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD0BYsEsgUrm",
        "outputId": "b6e1e28d-3b67-4692-b96c-fcef08343b15"
      },
      "source": [
        "!echo '{\"sentence\": \"Now, ice pucks guys!\"}' |\\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-24 22:56:23,345 - INFO - transformers.file_utils - PyTorch version 1.5.1 available.\n",
            "2021-10-24 22:56:25,209 - INFO - transformers.file_utils - TensorFlow version 2.6.0 available.\n",
            "2021-10-24 22:56:26,488 - INFO - allennlp.common.file_utils - checking cache for https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:56:26,488 - INFO - allennlp.common.file_utils - waiting to acquire lock on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:56:26,488 - INFO - filelock - Lock 139869295763344 acquired on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2021-10-24 22:56:26,488 - INFO - allennlp.common.file_utils - cache of https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz is up-to-date\n",
            "2021-10-24 22:56:26,488 - INFO - filelock - Lock 139869295763344 released on /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724.lock\n",
            "2021-10-24 22:56:26,488 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz from cache at /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724\n",
            "2021-10-24 22:56:26,489 - INFO - allennlp.models.archival - extracting archive file /root/.allennlp/cache/e20d5b792a8d456a1a61da245d1856d4b7778efe69ac3c30759af61940aa0f42.f72523a9682cb1f5ad3ecf834075fe53a1c25a6bcbf4b40c11e13b7f426a4724 to temp dir /tmp/tmpkx1iqn1r\n",
            "2021-10-24 22:56:30,888 - INFO - allennlp.common.params - type = from_instances\n",
            "2021-10-24 22:56:30,888 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpkx1iqn1r/vocabulary.\n",
            "2021-10-24 22:56:30,888 - INFO - filelock - Lock 139869293525648 acquired on /tmp/tmpkx1iqn1r/vocabulary/.lock\n",
            "2021-10-24 22:56:30,913 - INFO - filelock - Lock 139869293525648 released on /tmp/tmpkx1iqn1r/vocabulary/.lock\n",
            "2021-10-24 22:56:30,913 - INFO - allennlp.common.params - model.type = srl_bert\n",
            "2021-10-24 22:56:30,914 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2021-10-24 22:56:30,914 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
            "2021-10-24 22:56:30,914 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
            "2021-10-24 22:56:30,914 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f35db8b0fd0>\n",
            "2021-10-24 22:56:30,914 - INFO - allennlp.common.params - model.label_smoothing = None\n",
            "2021-10-24 22:56:30,914 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
            "2021-10-24 22:56:30,914 - INFO - allennlp.common.params - model.srl_eval_path = /usr/local/lib/python3.7/dist-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
            "2021-10-24 22:56:31,188 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2021-10-24 22:56:31,188 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "2021-10-24 22:56:31,258 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2021-10-24 22:56:33,955 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2021-10-24 22:56:33,956 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2021-10-24 22:56:33,956 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
            "2021-10-24 22:56:33,956 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
            "2021-10-24 22:56:33,956 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,957 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
            "2021-10-24 22:56:33,958 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,959 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
            "2021-10-24 22:56:33,960 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
            "2021-10-24 22:56:33,961 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
            "2021-10-24 22:56:33,962 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
            "2021-10-24 22:56:33,963 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
            "2021-10-24 22:56:33,964 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
            "2021-10-24 22:56:33,964 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
            "2021-10-24 22:56:33,982 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
            "2021-10-24 22:56:33,982 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
            "2021-10-24 22:56:33,982 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
            "2021-10-24 22:56:33,982 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,982 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,982 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
            "2021-10-24 22:56:33,982 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
            "2021-10-24 22:56:33,983 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
            "2021-10-24 22:56:33,984 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,984 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,984 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
            "2021-10-24 22:56:33,984 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
            "2021-10-24 22:56:33,985 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
            "2021-10-24 22:56:33,985 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
            "2021-10-24 22:56:33,985 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
            "2021-10-24 22:56:33,985 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
            "2021-10-24 22:56:33,985 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
            "2021-10-24 22:56:33,985 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
            "2021-10-24 22:56:33,985 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
            "2021-10-24 22:56:33,986 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
            "2021-10-24 22:56:33,986 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2021-10-24 22:56:33,986 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2021-10-24 22:56:33,986 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
            "2021-10-24 22:56:33,986 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
            "2021-10-24 22:56:33,986 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
            "2021-10-24 22:56:33,986 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
            "2021-10-24 22:56:33,986 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
            "2021-10-24 22:56:33,986 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
            "2021-10-24 22:56:34,616 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
            "2021-10-24 22:56:34,617 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2021-10-24 22:56:34,617 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2021-10-24 22:56:34,617 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
            "2021-10-24 22:56:34,617 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2021-10-24 22:56:34,617 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2021-10-24 22:56:34,617 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
            "2021-10-24 22:56:34,617 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
            "2021-10-24 22:56:34,617 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
            "2021-10-24 22:56:34,923 - INFO - transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "input 0:  {\"sentence\": \"Now, ice pucks guys!\"}\n",
            "prediction:  {\"verbs\": [], \"words\": [\"Now\", \",\", \"ice\", \"pucks\", \"guys\", \"!\"]}\n",
            "\n",
            "2021-10-24 22:56:35,907 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpkx1iqn1r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiKwBtBAhHNz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}